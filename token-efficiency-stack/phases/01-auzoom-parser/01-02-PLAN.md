# PLAN 01-02: AuZoom Graph Navigation & Fetch Levels

## Objective
Implement the graph structure that connects CodeNodes and the fetch-level system that returns appropriate resolution based on request.

## Context
```
@STATE.md
@auzoom/models.py
@auzoom/parser.py
```

## Tasks

<task type="auto">
  <n>Implement CodeGraph container</n>
  <files>auzoom/graph.py</files>
  <action>
    class CodeGraph:
        def __init__(self):
            self.nodes: dict[str, CodeNode] = {}  # id -> node
            self.file_index: dict[str, list[str]] = {}  # file_path -> node_ids
            
        def add_node(self, node: CodeNode) -> None: ...
        
        def get_node(self, node_id: str, level: FetchLevel) -> dict:
            # Return node at requested resolution
            
        def get_file(self, file_path: str, level: FetchLevel) -> list[dict]:
            # Return all nodes in file at resolution
            
        def get_children(self, node_id: str, level: FetchLevel) -> list[dict]: ...
        
        def get_dependencies(self, node_id: str, depth: int = 1) -> list[dict]:
            # Return dependency nodes (for context building)
            
        def get_dependents(self, node_id: str, depth: int = 1) -> list[dict]:
            # Return nodes that depend on this one (impact analysis)
  </action>
  <verify>
    python -c "from auzoom.graph import CodeGraph; g = CodeGraph(); print('Graph OK')"
  </verify>
  <done>CodeGraph with navigation methods implemented</done>
</task>

<task type="auto">
  <n>Implement token-aware formatting</n>
  <files>auzoom/formatter.py</files>
  <action>
    def format_skeleton(node: CodeNode) -> str:
        # "def function_name(args) -> deps: [dep1, dep2]"
        # Target: ~15 tokens per node
        
    def format_summary(node: CodeNode) -> str:
        # Skeleton + docstring (truncated to 100 chars if longer)
        # Target: ~75 tokens per node
        
    def format_full(node: CodeNode) -> str:
        # Complete source code
        # Target: actual size
        
    def estimate_tokens(text: str) -> int:
        # Rough estimate: chars / 4
        
    Include token count in output for monitoring.
  </action>
  <verify>
    Parse test file, format at each level, verify skeleton < summary < full token counts
  </verify>
  <done>Three format levels produce appropriate token counts</done>
</task>

<task type="auto">
  <n>Create integration test</n>
  <files>tests/test_auzoom_core.py</files>
  <action>
    Test with real-world Python file (use a file from requests or similar library):
    
    def test_parse_real_file():
        parser = PythonParser()
        graph = CodeGraph()
        nodes = parser.parse_file("vendor/example.py")
        for node in nodes:
            graph.add_node(node)
        
        # Verify token reduction
        full_tokens = sum(estimate_tokens(format_full(n)) for n in nodes)
        skeleton_tokens = sum(estimate_tokens(format_skeleton(n)) for n in nodes)
        
        assert skeleton_tokens < full_tokens * 0.1  # 10x reduction minimum
        
    def test_dependency_traversal():
        # Verify get_dependencies returns connected nodes
        
    def test_level_escalation():
        # skeleton -> summary -> full returns progressively more
  </action>
  <verify>pytest tests/test_auzoom_core.py -v</verify>
  <done>Tests pass, demonstrating 10x+ token reduction</done>
</task>

## Verification
- [ ] CodeGraph stores and retrieves nodes by ID and file
- [ ] Dependency traversal works bidirectionally  
- [ ] Token estimates show ≥10x reduction for skeleton vs full
- [ ] Tests pass

## Success Criteria
Integration test proves skeleton level uses ≤10% of full tokens.

## Output
Update STATE.md with: token reduction ratio, dependency accuracy notes.
SUMMARY.md only if major issues or stopping.
