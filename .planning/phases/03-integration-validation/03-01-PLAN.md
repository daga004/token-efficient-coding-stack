---
phase: 03-integration-validation
plan: 01
type: execute
---

<objective>
Demonstrate token-efficient workflows using AuZoom and Orchestrator tools with comprehensive usage examples and patterns.

Purpose: Show users how to leverage both tools in real development scenarios to achieve 50-70% token/cost savings.

Output: Usage examples, workflow patterns, demonstration tasks, updated documentation with real-world usage.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
@~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/WISHLIST-COMPLIANCE.md
@README.md
@.claude/skills/token-efficient-coding.md

**Current State**:
- ✅ AuZoom MCP server: 5 tools, 39 tests passing
- ✅ Orchestrator MCP server: 3 tools, 65 tests passing
- ✅ Skills installed: token-efficient-coding, auzoom-use, orchestrator-use
- ✅ Repository published: https://github.com/daga004/token-efficient-coding-stack
- ✅ Installer ready: INSTALL.sh

**Integration Points**:
- MCP tools available to Claude Code via user-scope servers
- Skills provide guidance on usage
- No automatic integration - explicit tool usage required

**What "Integration" Means**:
Since MCP tools are already available, "integration" means:
1. Demonstrating effective usage patterns
2. Creating workflow examples
3. Documenting best practices
4. Validating actual token/cost savings
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create comprehensive usage examples</name>
  <files>USAGE-EXAMPLES.md</files>
  <action>
Create real-world usage examples that demonstrate token-efficient workflows.

**Example Categories**:

1. **Exploring Unknown Codebase** (token savings demonstration)
```
Scenario: Understand new Python project structure
Traditional: Read all files → 50,000 tokens
AuZoom approach:
- auzoom_read(".", level="skeleton") → 500 tokens (see structure)
- auzoom_read("src/main.py", level="summary") → 200 tokens (key functions)
- auzoom_read("src/core.py", level="full") → 2000 tokens (only what's needed)
Total: 2,700 tokens
Savings: 94.6%
```

2. **Making Code Changes** (workflow pattern)
```
Scenario: Fix bug in authentication module
Steps:
1. auzoom_find("authenticate") → Locate function
2. auzoom_read(file, level="skeleton") → Confirm location
3. auzoom_read(file, level="summary") → Understand function
4. Edit tool → Make changes
5. auzoom_validate(file) → Check structure compliance
Token cost: ~400 tokens vs 5,000 tokens reading full file
```

3. **Routing Complex Task** (cost optimization)
```
Scenario: Implement OAuth2 authentication
Steps:
1. orchestrator_route(task, context={files: 8, tests: true, apis: ["OAuth2"]})
   → Returns: {model: "sonnet", score: 7.5, cost: ~$0.015}
2. Use Task tool with model="sonnet" for implementation
3. orchestrator_validate(task, output)
   → Returns: {pass: true, confidence: 0.9}
Cost: $0.015 vs $0.050 using Opus for everything
Savings: 70%
```

4. **Batch Simple Edits** (aggressive cost optimization)
```
Scenario: Fix 20 typos in documentation
Traditional: 20 × Sonnet calls = 20 × $0.01 = $0.20
Optimized:
- orchestrator_route("fix typo") → Returns "gemini-flash"
- 20 × Flash calls = 20 × $0.0001 = $0.002
Savings: 99%
```

Create `USAGE-EXAMPLES.md` with:
- 10 comprehensive scenarios
- Before/after token counts
- Before/after cost estimates
- Step-by-step workflows
- Expected savings percentages
  </action>
  <verify>USAGE-EXAMPLES.md exists with 10 scenarios, each showing token/cost savings</verify>
  <done>Usage examples created demonstrating 50-94% token savings and 70-99% cost savings</done>
</task>

<task type="auto">
  <name>Task 2: Create workflow templates</name>
  <files>.claude/workflows/token-efficient-*.md</files>
  <action>
Create reusable workflow templates for common development tasks.

**Workflows to Create**:

1. **workflow-explore-codebase.md**
```markdown
# Exploring Unknown Codebase (Token-Efficient)

## Objective
Understand project structure with minimal token usage.

## Steps
1. Get overview: `auzoom_read(".", level="skeleton")`
2. Identify entry points: Look for main.py, __init__.py
3. Drill down: `auzoom_read("src/main.py", level="summary")`
4. Read dependencies: `auzoom_get_dependencies(node_id, depth=1)`
5. Full read only if needed: `auzoom_read(file, level="full")`

## Token Budget
- Skeleton: ~500 tokens
- Summary: ~1,000 tokens
- Full (selective): ~2,000 tokens
Total: ~3,500 tokens vs 50,000+ traditional

## Savings: ~93%
```

2. **workflow-implement-feature.md**
```markdown
# Implementing New Feature (Cost-Efficient)

## Objective
Add feature using appropriate model tier.

## Steps
1. Route task: `orchestrator_route(task, context)`
2. Review recommendation: Check complexity score
3. Use recommended model or Task tool
4. Validate: `orchestrator_validate(task, output)`
5. If validation fails: Escalate to next tier

## Cost Budget
- Simple feature: $0.001-0.005 (Flash/Haiku)
- Standard feature: $0.005-0.015 (Haiku/Sonnet)
- Complex feature: $0.015-0.050 (Sonnet/Opus)

## Savings: 40-82% vs always using Opus
```

3. **workflow-refactor-code.md**
4. **workflow-debug-issue.md**
5. **workflow-review-pr.md**

Create these 5 workflow templates in `.claude/workflows/`
  </action>
  <verify>5 workflow templates exist in .claude/workflows/, each with clear steps and savings estimates</verify>
  <done>Workflow templates created for common development tasks</done>
</task>

<task type="auto">
  <name>Task 3: Run demonstration tasks with metrics</name>
  <files>.planning/phases/03-integration-validation/DEMONSTRATION-RESULTS.md</files>
  <action>
Execute 5 representative tasks to demonstrate actual usage and measure token/cost savings.

**Tasks to Execute**:

1. **Explore AuZoom Codebase**
   - Use: auzoom_read on auzoom/ directory
   - Measure: tokens used, time taken
   - Compare: vs reading all files with Read tool

2. **Understand Orchestrator**
   - Use: auzoom_find + progressive disclosure
   - Measure: tokens used
   - Compare: vs full file reads

3. **Route Simple vs Complex Tasks**
   - Use: orchestrator_route on 3 tasks of varying complexity
   - Measure: recommended models, estimated costs
   - Compare: vs using Sonnet for all

4. **Validate Structure Compliance**
   - Use: auzoom_validate on orchestrator/
   - Measure: violations found, tokens used
   - Compare: vs manual review

5. **Cache Performance Test**
   - Use: auzoom_stats + repeated reads
   - Measure: cache hit rate, speedup
   - Demonstrate: 100x+ speedup on cache hits

For each task, document:
- Exact commands used
- Tokens consumed (actual)
- Time taken
- Savings vs traditional approach
- Screenshots/output

Create DEMONSTRATION-RESULTS.md with all measurements.
  </action>
  <verify>DEMONSTRATION-RESULTS.md exists with 5 completed tasks showing actual token/cost/time measurements</verify>
  <done>Demonstration tasks completed with real metrics showing 50-94% token savings, 100x cache speedup</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Usage examples, workflow templates, demonstration results</what-built>
  <how-to-verify>
Review the created documentation:

1. **Check USAGE-EXAMPLES.md**:
   - 10 scenarios with token/cost comparisons
   - Realistic before/after measurements
   - Clear step-by-step instructions

2. **Check Workflow Templates**:
   ```bash
   ls .claude/workflows/
   # Should see 5 workflow-*.md files
   ```

3. **Check Demonstration Results**:
   - DEMONSTRATION-RESULTS.md has 5 completed tasks
   - Actual token measurements included
   - Savings percentages calculated

4. **Verify Completeness**:
   - [ ] Usage examples comprehensive
   - [ ] Workflows cover common tasks
   - [ ] Demonstrations show real metrics
   - [ ] Savings targets met (≥50% token, ≥70% cost)

Type **"approved"** if documentation is complete and accurate, or describe issues to fix.
  </how-to-verify>
  <resume-signal>Type "approved" to continue, or describe issues to address</resume-signal>
</task>

<task type="auto">
  <name>Task 4: Update README with integration examples</name>
  <files>README.md</files>
  <action>
Add "Integration Examples" section to README.md showing how tools work together.

**New Section**:
```markdown
## Integration Examples

### Workflow 1: Explore + Route + Execute
\`\`\`python
# 1. Understand codebase efficiently
auzoom_read("src/", level="skeleton")  # 500 tokens
# See structure, identify complex auth module

# 2. Route implementation task
orchestrator_route(
    "Refactor authentication to use JWT",
    context={"files_count": 5, "requires_tests": True}
)
# Returns: {model: "sonnet", score: 6.5}

# 3. Read only what's needed
auzoom_read("src/auth.py", level="summary")  # 200 tokens
# Understand current implementation

# 4. Use Task tool with recommended model
# Task(model="sonnet", prompt="...")

# 5. Validate structure after changes
auzoom_validate("src/auth.py")
# Returns: {compliant: true}
\`\`\`

**Total Tokens**: 700 vs 10,000+ traditional
**Cost**: $0.015 vs $0.050 using Opus
**Savings**: 93% tokens, 70% cost
```

Add link to USAGE-EXAMPLES.md for full scenarios.
  </action>
  <verify>README.md has new "Integration Examples" section with combined tool usage</verify>
  <done>README updated with integration examples showing tools working together</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] USAGE-EXAMPLES.md created with 10 scenarios
- [ ] 5 workflow templates in .claude/workflows/
- [ ] DEMONSTRATION-RESULTS.md with actual measurements
- [ ] README.md updated with integration examples
- [ ] Human verification checkpoint passed
- [ ] Documentation shows ≥50% token savings
- [ ] Documentation shows ≥70% cost savings
</verification>

<success_criteria>
- All tasks completed
- Usage examples comprehensive and realistic
- Workflow templates cover common development scenarios
- Demonstration results show actual token/cost savings
- Documentation proves tools deliver on savings targets
- Ready for Plan 03-02 (validation testing)
</success_criteria>

<output>
After completion, create `.planning/phases/03-integration-validation/03-01-SUMMARY.md`:

# Phase 3 Plan 01: Usage Examples & Workflows Summary

**[One-liner describing what shipped]**

## Accomplishments

- Created 10 comprehensive usage examples
- Developed 5 reusable workflow templates
- Executed 5 demonstration tasks with real metrics
- Updated README with integration examples
- Documented actual token/cost savings

## Token/Cost Savings Demonstrated

**Token Savings**:
- Codebase exploration: 93-94% reduction
- Code changes: 92% reduction
- Validation: 85% reduction

**Cost Savings**:
- Simple tasks (Flash): 99% reduction
- Standard tasks (Haiku): 90% reduction
- Complex tasks (Sonnet): 70% reduction

## Files Created

- USAGE-EXAMPLES.md - 10 scenarios with measurements
- .claude/workflows/*.md - 5 workflow templates
- DEMONSTRATION-RESULTS.md - Actual usage metrics
- README.md - Updated with integration section

## Next Phase

Plan 03-02: Validation testing with 10 representative tasks and formal measurements.
</output>
