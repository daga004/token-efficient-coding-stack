---
phase: 06.5-progressive-traversal-validation
plan: 02
type: execute
---

<objective>
Compare progressive traversal vs upfront full read approaches on same 10 tasks to measure net token savings accounting for conversation overhead and assess quality parity.

Purpose: Determine if progressive on-demand depth selection saves tokens vs traditional "read everything upfront" approach when including all overhead costs.
Output: Comparative analysis report with net savings calculation, quality parity verification, and recommendation on when to use progressive vs upfront.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06.5-progressive-traversal-validation/CONTEXT.md

# Prior plan results
@.planning/phases/06.5-progressive-traversal-validation/06.5-01-SUMMARY.md

# Interaction patterns from Plan 01
@audit/reports/06.5-01-interaction-patterns.md
@audit/evidence/progressive_traversal_*.jsonl

**Plan 01 provided**: Depth progression patterns, conversation overhead measurements
**This plan adds**: Direct comparison to upfront baseline, net savings calculation
</context>

<tasks>

<task type="auto">
  <name>Task 1: Execute baseline approach (upfront full read) for all 10 tasks</name>
  <files>audit/baseline_executor.py, audit/evidence/baseline_upfront_*.jsonl</files>
  <action>Execute same 10 tasks from Plan 01, but with **traditional approach**:

**Baseline approach**:
- Agent starts with full read of all potentially relevant files
- No progressive traversal
- Single large context upfront

```python
class BaselineExecutor:
    def execute_task(self, task_id, description):
        # Identify relevant files (same as progressive approach would discover)
        # Read all files at FULL level immediately
        # Agent completes task with full context

        # Measure:
        result = {
            "task_id": task_id,
            "description": description,
            "files_read": ["file1.py", "file2.py"],
            "tokens_per_file": [450, 680],
            "total_tokens": 1130,
            "quality": "correct",
            "time_to_complete": "45s",
        }
        return result
```

**Fair comparison**:
- Use same task descriptions
- Agent has same tools available (except auzoom - just Read tool)
- Validate output quality against same success criteria

**Critical**: Baseline should read the SAME files that progressive approach discovered. Don't penalize baseline for reading extra files (that's graph navigation benefit, measured in Plan 03).

For each task:
1. Spawn Task agent with Read tool only
2. Agent reads files at full depth upfront
3. Measure total tokens consumed
4. Validate quality against success criteria

Write results to: `audit/evidence/baseline_upfront_20260113_*.jsonl`
</action>
  <verify>10 baseline executions complete, evidence file has token measurements and quality scores</verify>
  <done>Baseline approach executed for all 10 tasks with upfront full reads</done>
</task>

<task type="auto">
  <name>Task 2: Calculate net savings accounting for all overhead</name>
  <files>audit/net_savings_calculator.py, audit/net_savings.json</files>
  <action>Compare progressive (Plan 01) vs baseline (Task 1) token consumption:

## Net Savings Formula

For each task:
```
progressive_total = sum(auzoom_read_tokens) + conversation_overhead
baseline_total = sum(read_tool_tokens)
net_savings = (baseline_total - progressive_total) / baseline_total × 100%
```

**Conversation overhead** includes:
- Agent reasoning between depth decisions
- Follow-up request formulation
- Context summarization if needed

## Task-by-Task Comparison

| Task | Progressive | Baseline | Net Savings | Verdict |
|------|-------------|----------|-------------|---------|
| 1 (shallow) | 150 + 10 = 160 | 450 | +64% | ✅ WIN |
| 2 (shallow) | 150 + 15 = 165 | 680 | +76% | ✅ WIN |
| 3 (medium) | 150 + 50 + 1,125 = 1,325 | 450 | -194% | ❌ LOSS |
| ... | ... | ... | ... | ... |
| 10 (graph) | 150 + 20 = 170 | 1,200 | +86% | ✅ WIN |

## Aggregate Metrics

Calculate:
- **Average net savings**: Mean across all 10 tasks
- **Win rate**: % of tasks with positive savings
- **Loss magnitude**: How bad are the losses?
- **By task type**:
  - Shallow tasks: [X]% average savings
  - Medium tasks: [Y]% average savings
  - Deep tasks: [Z]% average savings
  - Graph tasks: [W]% average savings

## Breakeven Analysis

At what file size does progressive become beneficial?
- Small files (<300 lines): Progressive typically adds overhead
- Medium files (300-1000 lines): Mixed results
- Large files (>1000 lines): Progressive typically saves

**Calculate threshold**:
- File size where net savings = 0%
- Recommendation: Use progressive only for files > [X] lines

Store results: `audit/net_savings.json`
```json
{
  "overall": {
    "average_net_savings": 15.3,
    "win_rate": 0.70,
    "tasks_with_savings": 7,
    "tasks_with_overhead": 3
  },
  "by_type": {
    "shallow": {"avg_savings": 68.5, "win_rate": 1.0},
    "medium": {"avg_savings": -95.2, "win_rate": 0.33},
    "deep": {"avg_savings": -45.7, "win_rate": 0.0},
    "graph": {"avg_savings": 78.4, "win_rate": 1.0}
  },
  "breakeven_file_size": 650
}
```
</action>
  <verify>cat audit/net_savings.json shows complete comparison with aggregate metrics</verify>
  <done>Net savings calculated for all tasks, breakeven analysis complete</done>
</task>

<task type="auto">
  <name>Task 3: Quality parity verification and comparative analysis report</name>
  <files>audit/reports/06.5-02-progressive-vs-upfront.md</files>
  <action>Generate comprehensive comparison report:

# Progressive vs Upfront: Comprehensive Comparison

## Executive Summary

**Overall verdict**: Progressive traversal [SAVES / COSTS MORE / NEUTRAL] compared to upfront full read

**Key metrics**:
- Average net savings: [X]% (target: ≥20%)
- Win rate: [Y]% of tasks (target: ≥60%)
- Quality parity: [Z]% (target: 100%)

---

## 1. Token Efficiency Comparison

### Overall Results

| Metric | Progressive | Baseline | Difference |
|--------|-------------|----------|------------|
| Total tokens (10 tasks) | [X] | [Y] | [±Z]% |
| Average per task | [X] | [Y] | [±Z]% |
| Conversation overhead | [X] | N/A | [Z]% of progressive total |

### Task-by-Task Results

[Table showing all 10 tasks with progressive vs baseline tokens]

### By Task Type

**Shallow tasks** (skeleton sufficient):
- Progressive: [X] avg tokens
- Baseline: [Y] avg tokens
- Net savings: [Z]%
- **Verdict**: Progressive [WINS / LOSES / NEUTRAL]

**Medium tasks** (summary sufficient):
- Progressive: [X] avg tokens
- Baseline: [Y] avg tokens
- Net savings: [Z]%
- **Verdict**: Progressive [WINS / LOSES / NEUTRAL]

**Deep tasks** (full read required):
- Progressive: [X] avg tokens
- Baseline: [Y] avg tokens
- Net savings: [Z]%
- **Verdict**: Progressive [WINS / LOSES / NEUTRAL]

**Graph tasks** (dependency traversal):
- Progressive: [X] avg tokens
- Baseline: [Y] avg tokens
- Net savings: [Z]%
- **Verdict**: Progressive [WINS / LOSES / NEUTRAL]

---

## 2. Quality Parity Analysis

For each task:
- Progressive quality: [%]
- Baseline quality: [%]
- Parity maintained? YES / NO

**Overall quality parity**: [X]% of tasks maintained equal quality

**Quality degradation cases**:
- Task [N]: Progressive [missed X / provided less detail]
- Root cause: [Agent stayed too shallow / missed context]

---

## 3. Conversation Overhead Analysis

**Overhead breakdown**:
- Average overhead per task: [X] tokens
- As % of progressive total: [Y]%
- Is overhead significant? [YES / NO]

**Pattern analysis**:
- Shallow tasks: [X] avg overhead (low)
- Medium tasks: [Y] avg overhead (moderate)
- Deep tasks: [Z] avg overhead (high - multiple depth decisions)

**Overhead efficiency**:
- Is overhead justified by savings? [YES / NO / MIXED]

---

## 4. Breakeven Analysis

**When does progressive win?**
- File size threshold: [X] lines
- Task complexity: [shallow / medium / deep / graph]
- Use case: [exploration / implementation / debugging]

**Recommendations**:
- Use progressive for: [conditions]
- Use upfront for: [conditions]
- Hybrid approach: [strategy]

---

## 5. UX Considerations (Qualitative)

**Progressive advantages** (even if token-neutral):
- Better context control (agent decides what to load)
- Faster initial response (skeleton loads quickly)
- Lower memory footprint (don't load everything)
- More natural conversation flow

**Progressive disadvantages**:
- Multiple round trips (latency)
- Context fragmentation (agent may miss connections)
- Overhead from depth decisions

**Verdict**: Is UX benefit worth token overhead? [YES / NO]

---

## 6. Overall Recommendation

**Based on metrics**:
- Net savings: [X]% (target: ≥20%)
- Win rate: [Y]% (target: ≥60%)
- Quality parity: [Z]% (target: 100%)

**Verdict**: **[RECOMMEND PROGRESSIVE / RECOMMEND UPFRONT / RECOMMEND HYBRID]**

**Specific recommendations**:
1. For files < [X] lines: Use upfront full read (progressive adds overhead)
2. For files > [X] lines: Use progressive (saves tokens)
3. For shallow tasks: Always use progressive (skeleton sufficient)
4. For deep implementation: Consider upfront (reduces round trips)
5. For graph navigation: Always use progressive (dependency traversal efficient)

---

## 7. V1 Certification Impact

**Can V1 claim "progressive disclosure saves tokens"?**
- [YES, with caveats / NO, overhead exceeds savings / MIXED, depends on use case]

**Required claim revisions**:
- [List any changes needed to documentation]

**Implementation recommendations**:
- [Auto-detect file size threshold]
- [User preference toggle: progressive vs upfront]
- [Hybrid mode: progressive for large, upfront for small]
</action>
  <verify>cat audit/reports/06.5-02-progressive-vs-upfront.md shows comprehensive comparison with recommendations</verify>
  <done>Comparative analysis complete, recommendations for progressive vs upfront delivered</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Baseline approach executed for all 10 tasks
- [ ] Net savings calculated accounting for conversation overhead
- [ ] Quality parity verified (progressive = baseline quality)
- [ ] Task-type breakdown complete (shallow, medium, deep, graph)
- [ ] Breakeven analysis identifies file size threshold
- [ ] Recommendations provided for when to use progressive vs upfront
</verification>

<success_criteria>
- All 10 tasks executed with both approaches
- Net savings ≥20% OR net savings ≥0% with documented UX benefit
- Quality parity maintained (≥95% match)
- Clear recommendations on when progressive is beneficial
- V1 certification impact assessed
</success_criteria>

<output>
After completion, create `06.5-02-SUMMARY.md`:

# Phase 6.5 Plan 02: Progressive vs Upfront Comparison Summary

**[One-liner about net token savings and when progressive approach is beneficial]**

## Accomplishments

- Baseline approach executed for all 10 tasks (upfront full read)
- Net savings calculated: [X]% average (target: ≥20%)
- Quality parity verified: [Y]% tasks maintained equal quality
- Breakeven analysis: Progressive beneficial for files > [Z] lines
- Use case recommendations: [when to use progressive vs upfront]

## Key Findings

**Token Efficiency**:
- Overall net savings: [X]%
- Win rate: [Y]% of tasks
- By type: Shallow +[A]%, Medium -[B]%, Deep -[C]%, Graph +[D]%

**Quality Parity**:
- [N]/10 tasks maintained 100% quality match
- [N] tasks with degradation from progressive approach
- Overall quality parity: [X]%

**Conversation Overhead**:
- Average [X] tokens per task
- [Y]% of progressive total
- Overhead [IS / IS NOT] justified by savings

## Verdict

Progressive traversal: **[NET POSITIVE / NET NEGATIVE / CONTEXT-DEPENDENT]**

[Explanation based on metrics]

## Recommendations

**Use progressive for**:
- Files > [X] lines
- Shallow exploration tasks
- Graph navigation tasks

**Use upfront for**:
- Files < [X] lines (overhead exceeds benefit)
- Deep implementation tasks (reduces round trips)
- When multiple files needed simultaneously

**Hybrid approach**:
[Strategy for combining both based on context]

## V1 Impact

[Can V1 claim progressive saves tokens? What revisions needed?]
</output>
