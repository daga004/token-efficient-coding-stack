---
phase: 02-orchestrator-implementation
plan: 02-v2
type: execute
status: revised
---

<objective>
Implement model dispatch layer with Gemini CLI and Claude Code Task tool for executing tasks on routed models.

Purpose: Enable orchestrator to execute tasks on Gemini Flash/Pro (via CLI) and Claude models (Haiku/Sonnet/Opus via Task tool), with unified interface, error handling, and retry logic.

**CRITICAL ARCHITECTURE CHANGE**: NO direct Anthropic API usage. Claude model switching happens via Claude Code's Task tool with `model` parameter.

Output: Working dispatch layer with Gemini CLI wrapper, Claude Task tool wrapper, unified execution interface, retry/fallback logic, and test coverage.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-orchestrator-implementation/02-01-SUMMARY.md

**Existing code from Plan 02-01:**
- ComplexityScorer: Rule-based 0-10 scoring
- ModelRegistry: 4-tier system (Flash, Haiku, Sonnet, Opus)
- Task and TaskComplexity models

**Existing code from Plan 02-02 (partial):**
- ✅ Gemini CLI wrapper (orchestrator/src/orchestrator/clients/gemini.py) - KEEP
- ✅ Base interfaces (orchestrator/src/orchestrator/clients/base.py) - KEEP
- ❌ Anthropic API client - REMOVED (violated architecture requirement)
- ❌ Direct API executor - REMOVED

**Correct Architecture:**
1. **Gemini models** (Flash, Pro): Use CLI via subprocess (EXTERNAL)
2. **Claude models** (Haiku, Sonnet, Opus): Use Task tool with `model` parameter (INTERNAL)
3. **NO direct Anthropic API calls** - violates user requirement

**Tech stack:**
- Gemini CLI: subprocess execution for Gemini models
- Task tool: Claude Code's native model switching for Claude models
- Unified ExecutionResult for all clients
- Follow AuZoom standards (≤250 lines/module, ≤50 lines/function)

**Use AuZoom for all file reads:**
- `mcp__auzoom__auzoom_read` for reading code
- Progressive disclosure: skeleton → summary → full
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement Claude Task tool wrapper</name>
  <files>orchestrator/src/orchestrator/clients/claude_task.py</files>
  <action>
Create ClaudeTaskClient that routes tasks to Claude models via Task tool:

```python
from .base import ExecutionResult, ModelClient
import time
import asyncio

class ClaudeTaskClient(ModelClient):
    """Client for executing prompts via Claude Code's Task tool with model routing."""

    # Model name mapping from registry to Task tool
    MODEL_MAP = {
        "haiku": "haiku",
        "sonnet": "sonnet",
        "opus": "opus"
    }

    def __init__(self, model: str = "haiku"):
        """
        Initialize Claude Task client.

        Args:
            model: Model identifier (haiku, sonnet, or opus)
        """
        self.model = model

    async def execute(self, prompt: str, max_tokens: int = 4096) -> ExecutionResult:
        """
        Execute a prompt via Claude Code Task tool with specified model.

        This uses Claude Code's native Task spawning capability to run
        the prompt on a specific Claude model without direct API calls.

        Args:
            prompt: The input prompt/task to execute
            max_tokens: Maximum number of output tokens (hint for Task tool)

        Returns:
            ExecutionResult with response and metadata
        """
        start_time = time.time()
        model_id = self.MODEL_MAP.get(self.model, self.model)

        try:
            # Use Task tool to spawn sub-agent with specific model
            # This is a placeholder - actual implementation would use
            # Claude Code's internal Task spawning mechanism

            # In practice, this would be called by the orchestrator MCP server
            # which has access to Claude Code's Task tool

            # For testing/standalone use, return a mock response
            response_text = f"[Task executed on {model_id} - implement Task tool integration in MCP server]"

            # Estimate tokens (rough: 4 chars = 1 token)
            tokens_input = len(prompt) // 4
            tokens_output = len(response_text) // 4

            return ExecutionResult(
                model=self.model,
                response=response_text,
                tokens_input=tokens_input,
                tokens_output=tokens_output,
                latency_ms=int((time.time() - start_time) * 1000),
                success=True
            )

        except Exception as e:
            return ExecutionResult(
                model=self.model,
                response="",
                tokens_input=0,
                tokens_output=0,
                latency_ms=int((time.time() - start_time) * 1000),
                success=False,
                error=f"Task tool error: {str(e)}"
            )
```

**Key Design:**
- ClaudeTaskClient provides unified interface like GeminiClient
- Actual Task spawning happens in MCP server (Plan 02-03)
- For standalone testing, returns placeholder responses
- Real implementation will integrate with Claude Code's Task API

Keep module ≤250 lines. Test with mock Task calls.
  </action>
  <verify>pytest tests/test_claude_task.py passes with mocked Task tool, ExecutionResult returned correctly</verify>
  <done>Claude Task client complete with unified interface, placeholder for MCP integration, tests passing</done>
</task>

<task type="auto">
  <name>Task 2: Create unified executor with correct routing</name>
  <files>orchestrator/src/orchestrator/executor.py</files>
  <action>
Implement Executor class that routes to correct client based on model tier:

```python
from .clients.gemini import GeminiClient
from .clients.claude_task import ClaudeTaskClient
from .registry import ModelRegistry, ModelTier
from .clients.base import ExecutionResult
import asyncio

class Executor:
    """
    Unified executor that routes tasks to appropriate models.

    Architecture:
    - Gemini models (Flash, Pro): External CLI
    - Claude models (Haiku, Sonnet, Opus): Task tool (internal)
    """

    def __init__(self):
        self.gemini = GeminiClient()
        self.claude_task = ClaudeTaskClient()
        self.registry = ModelRegistry()

    async def execute(
        self,
        model_tier: ModelTier,
        prompt: str,
        max_tokens: int = 4096,
        retry_count: int = 2
    ) -> ExecutionResult:
        """
        Execute task on specified model tier with retry logic.

        Args:
            model_tier: Target model tier for execution
            prompt: Input prompt/task to execute
            max_tokens: Maximum output tokens to generate
            retry_count: Number of retries on failure (default: 2)

        Returns:
            ExecutionResult with response and metadata

        Routing:
            - Tier 0 (Flash, Pro): Gemini CLI
            - Tier 1-3 (Haiku, Sonnet, Opus): Claude Task tool
        """
        # Select client and model based on tier
        if model_tier in [ModelTier.FLASH, ModelTier.PRO]:
            # External: Gemini CLI
            client = self.gemini
            model = "gemini-flash" if model_tier == ModelTier.FLASH else "gemini-pro"
        else:
            # Internal: Claude Code Task tool
            client = self.claude_task
            model_map = {
                ModelTier.HAIKU: "haiku",
                ModelTier.SONNET: "sonnet",
                ModelTier.OPUS: "opus"
            }
            model = model_map[model_tier]

        # Retry loop with exponential backoff
        last_result = None
        for attempt in range(retry_count + 1):
            result = await client.execute(prompt, max_tokens)

            if result.success:
                return result

            last_result = result

            # If not last attempt, wait and retry
            if attempt < retry_count:
                backoff_seconds = 2 ** attempt
                await asyncio.sleep(backoff_seconds)

        # All retries failed - attempt fallback to next tier up
        if model_tier == ModelTier.FLASH:
            # Fallback Flash → Haiku
            return await self.execute(
                ModelTier.HAIKU,
                prompt,
                max_tokens,
                retry_count=0  # No retries on fallback
            )

        # No fallback available - return final failure
        return last_result

    async def validate_output(self, task: str, output: str) -> dict:
        """
        Validate output against task requirements.

        Uses Sonnet for validation (good for input-heavy tasks).

        Args:
            task: Original task description
            output: Output to validate

        Returns:
            Dictionary with validation results
        """
        validation_prompt = f\"\"\"<context>{task}</context>
<output_to_validate>{output}</output_to_validate>

Validate the output against the task requirements.
Respond ONLY with JSON:
{{"pass": bool, "issues": ["max 3 items"], "confidence": 0-1, "escalate": bool}}\"\"\"

        # Use Sonnet for validation
        client = ClaudeTaskClient(model="sonnet")
        result = await client.execute(validation_prompt, max_tokens=100)

        if not result.success:
            return {
                "pass": False,
                "issues": [result.error],
                "confidence": 0.0,
                "escalate": True
            }

        try:
            import json
            return json.loads(result.response)
        except json.JSONDecodeError:
            return {
                "pass": False,
                "issues": ["Invalid JSON response"],
                "confidence": 0.0,
                "escalate": True
            }
```

Keep ≤250 lines. Test retry logic and routing decisions.
  </action>
  <verify>pytest tests/test_executor.py passes, routing works correctly (Gemini for Tier 0, Claude Task for Tier 1-3), retry logic tested, fallback Flash→Haiku works</verify>
  <done>Unified executor complete with correct routing architecture, retry/fallback logic, validation method, comprehensive tests</done>
</task>

<task type="auto">
  <name>Task 3: Update dependencies and clean up</name>
  <files>orchestrator/pyproject.toml, orchestrator/src/orchestrator/clients/__init__.py</files>
  <action>
Update package configuration:

1. **Remove anthropic dependency** from pyproject.toml (not needed)
2. **Keep pydantic** (required for models)
3. **Update clients/__init__.py** to export correct clients:

```python
"""Model clients for orchestrator."""

from .base import ExecutionResult, ModelClient
from .gemini import GeminiClient
from .claude_task import ClaudeTaskClient

__all__ = [
    "ExecutionResult",
    "ModelClient",
    "GeminiClient",
    "ClaudeTaskClient",
]
```

4. **Verify all imports work**
5. **Run all tests** to ensure nothing broke

Keep package lightweight - only dependencies actually needed.
  </action>
  <verify>All tests pass, imports work correctly, no anthropic dependency in pyproject.toml</verify>
  <done>Package configuration updated, anthropic dependency removed, all clients properly exported</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] ClaudeTaskClient implements ModelClient interface correctly
- [ ] Executor routes Gemini models to CLI (Tier 0)
- [ ] Executor routes Claude models to Task tool (Tier 1-3)
- [ ] Retry logic works with exponential backoff
- [ ] Fallback logic prevents infinite loops (Flash→Haiku only)
- [ ] All tests pass without requiring actual API keys/CLI
- [ ] No anthropic dependency in pyproject.toml
- [ ] Code follows AuZoom standards (≤250 lines/module)
</verification>

<success_criteria>
- All tasks completed
- All tests pass (10+ client tests, 5+ executor tests)
- Gemini CLI and Claude Task clients functional
- Unified interface works seamlessly
- Correct architecture: NO direct Anthropic API
- Ready for MCP server integration (Plan 02-03)
</success_criteria>

<output>
After completion, create `.planning/phases/02-orchestrator-implementation/02-02-SUMMARY-v2.md`:

# Phase 2 Plan 02-v2: Model Dispatch Layer Summary (REVISED)

**Implemented correct architecture: Gemini CLI + Claude Task tool (NO direct Anthropic API)**

## Accomplishments

- Gemini CLI wrapper with subprocess execution (reused from previous attempt)
- Claude Task tool wrapper for Haiku/Sonnet/Opus routing
- Unified ModelClient interface and ExecutionResult
- Correct routing: Gemini=CLI, Claude=Task tool
- Retry logic with exponential backoff
- Fallback routing (Flash→Haiku on failure)
- Validation method using Task tool
- Removed incorrect Anthropic API client

## Architecture Correction

**Previous (WRONG):**
- Gemini → CLI ✓
- Claude → Direct Anthropic API ✗

**Current (CORRECT):**
- Gemini → CLI ✓
- Claude → Task tool (Claude Code internal routing) ✓

## Files Created/Modified

- `orchestrator/src/orchestrator/clients/base.py` - Shared interfaces (kept)
- `orchestrator/src/orchestrator/clients/gemini.py` - Gemini CLI client (kept)
- `orchestrator/src/orchestrator/clients/claude_task.py` - Claude Task tool wrapper (NEW)
- `orchestrator/src/orchestrator/executor.py` - Unified executor with correct routing (REVISED)
- `orchestrator/tests/test_*.py` - Test coverage
- `orchestrator/pyproject.toml` - Removed anthropic dependency

## Commits

- [Removed incorrect Anthropic API implementation]
- [feat(02-02-v2): implement Claude Task tool wrapper]
- [feat(02-02-v2): unified executor with correct routing]
- [docs(02-02-v2): complete revised model dispatch layer]

## Decisions Made

1. **Task tool over direct API**: Claude model routing via Claude Code's Task tool, not Anthropic SDK
2. **Placeholder implementation**: ClaudeTaskClient provides interface; actual Task spawning in MCP server (02-03)
3. **Removed anthropic dependency**: Not needed with Task tool approach
4. **Gemini CLI kept**: External model via CLI is correct approach
5. **Unified interface maintained**: Both clients implement ModelClient for seamless executor usage

## Issues Encountered

1. **Previous architecture violation**: Original plan used direct Anthropic API (against user requirement)
   - Fixed by removing anthropic_client.py and executor.py
   - Created new ClaudeTaskClient using Task tool
   - Revised executor to route correctly

2. **Task tool integration**: ClaudeTaskClient provides interface but actual implementation in MCP server
   - Documented clearly that MCP server (Plan 02-03) will integrate with Claude Code's Task API
   - For standalone testing, uses placeholder responses

## Next Step

Ready for 02-03-PLAN.md (MCP Server & Integration) - will integrate ClaudeTaskClient with Claude Code's actual Task spawning mechanism
</output>
