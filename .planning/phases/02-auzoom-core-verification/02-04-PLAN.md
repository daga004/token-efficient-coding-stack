---
phase: 02-auzoom-core-verification
plan: 04
type: execute
domain: auzoom-structured-code
---

<objective>
Measure actual token savings on real codebases to verify claims beyond the original validation suite.

Purpose: Test whether token reduction holds on diverse codebases (not just auzoom/orchestrator which are small, well-structured files).
Output: Token savings measurements on external codebases with comparison to ≥50% target and original 23% validation result.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/WISHLIST-COMPLIANCE.md

# Phase 2 prior work
@.planning/phases/02-auzoom-core-verification/02-01-SUMMARY.md
@.planning/phases/02-auzoom-core-verification/02-02-SUMMARY.md
@.planning/phases/02-auzoom-core-verification/02-03-SUMMARY.md

# Audit infrastructure
@audit/audit_harness.py
@audit/templates/test_template.py

# Baseline metrics
@audit/baseline/BASELINE-REPORT.md

**Established patterns from Phase 1:**
- Evidence-based audit with file:line citations
- AuditTest base class for test structure
- JSON Lines evidence collection

**Key decisions constraining this phase:**
- Token reduction target ≥50% missed (actual 23% in validation)
- Validation used small, well-structured files (bias concern)
- Must test on larger, messier real-world codebases
- Findings from 02-01 (progressive disclosure by file size) inform expectations
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create real codebase token savings test</name>
  <files>audit/tests/test_real_codebase_savings.py</files>
  <action>Create test using AuditTest base class to measure token savings on real external codebases. Select 3-4 diverse Python projects: (1) a large framework file (>500 lines, e.g., Django/Flask if available locally), (2) a medium utility module (200-400 lines), (3) a small helper file (<200 lines), (4) a complex nested project (test across 5-10 related files with dependencies). For each, simulate common task: "Find function X and understand its dependencies". Measure: baseline tokens (full read of all files needed), optimized tokens (skeleton search → summary for matches → full for selected → dependencies at summary level). Use tiktoken cl100k_base to count tokens. Calculate savings percentage. Record evidence: codebase name, file sizes, task description, baseline token count, optimized token count, savings %, comparison to ≥50% target. Test on actual local Python codebases if available (check ~/Documents, ~/.local, /usr/local/lib/python*), or use Claude Code codebase itself as a realistic test case. Avoid synthetic examples.</action>
  <verify>pytest audit/tests/test_real_codebase_savings.py -v passes, evidence JSON Lines written with token savings for 3+ codebases</verify>
  <done>Test executable, measures savings on 3+ diverse real codebases, evidence collected with baseline vs optimized tokens and savings percentages</done>
</task>

<task type="auto">
  <name>Task 2: Execute real codebase test and compare to validation results</name>
  <files>audit/evidence/real_codebase_savings_*.jsonl, audit/reports/02-04-real-codebase-savings.md</files>
  <action>Run test with pytest -v. Capture evidence to JSON Lines file. Analyze results: calculate average savings across all tested codebases. Compare to: (a) ≥50% target, (b) 23% validation result, (c) findings from 02-01 (progressive disclosure by file size). Segment results by file size category (small/medium/large). Create markdown report with: test methodology, codebases tested (file:line references), token savings table (codebase, file sizes, baseline tokens, optimized tokens, savings %), average savings overall and by size category, comparison to target and validation baseline, assessment of whether real-world usage meets token reduction assumption. If savings still below target, synthesize findings from 02-01 through 02-04 to explain root cause (file size bias? dependency graph overhead? validation test suite not representative?). Document whether Assumption 1 holds: "local code indexing with function-level dependency tracking reduces full-file reads" - True/Partially True/False with evidence.</action>
  <verify>Report exists at audit/reports/02-04-real-codebase-savings.md, evidence file has savings data for all test cases, report includes comparison to target and validation results, Assumption 1 assessment included</verify>
  <done>Evidence collected, report written with quantitative findings (average savings, comparison to targets), Assumption 1 verified or refuted with evidence, root cause synthesis if target missed</done>
</task>

<task type="auto">
  <name>Task 3: Create Phase 2 synthesis report</name>
  <files>audit/reports/02-PHASE-SYNTHESIS.md</files>
  <action>Synthesize findings from all 4 plans (02-01 through 02-04) into comprehensive Phase 2 report. Structure: (1) Assumption 1 statement: "Local code indexing with function-level dependency tracking reduces full-file reads", (2) Verification approach (4 plans: progressive disclosure, dependency tracking, bypass behavior, real codebase savings), (3) Findings summary table (plan, key metric, result, target/expected, gap), (4) Overall assessment: Does Assumption 1 hold? (Yes/Partially/No with severity: Validated/Minor Gap/Critical Gap), (5) Evidence summary (cite specific reports: 02-01 through 02-04), (6) Recommendations for Phase 12 (critical fixes if assumption violated, enhancements if minor gaps), (7) Updated gap analysis for WISHLIST-COMPLIANCE.md (token reduction status, dependency tracking accuracy, bypass incidents). Make this the authoritative Phase 2 deliverable that later phases reference.</action>
  <verify>Synthesis report exists at audit/reports/02-PHASE-SYNTHESIS.md, includes overall Assumption 1 verdict with evidence citations, recommendations documented</verify>
  <done>Phase 2 synthesis complete, Assumption 1 verified/refuted with comprehensive evidence, recommendations for Phase 12 documented</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Test runs successfully with pytest
- [ ] Token savings measured on 3+ real codebases
- [ ] Evidence JSON Lines file contains baseline vs optimized token counts
- [ ] Report documents savings percentages and comparison to targets
- [ ] Phase 2 synthesis report created with Assumption 1 assessment
- [ ] All 4 reports (02-01 through 02-04) referenced in synthesis
</verification>

<success_criteria>

- Test implemented using AuditTest base class
- Token savings measured on diverse real-world codebases
- Evidence collected for 3+ codebases with size variety
- Report documents comparison to ≥50% target and 23% validation result
- Phase 2 synthesis report provides comprehensive Assumption 1 verdict
- Phase 2 complete - all 4 plans executed
- No errors or warnings introduced
  </success_criteria>

<output>
After completion, create `.planning/phases/02-auzoom-core-verification/02-04-SUMMARY.md`:

# Phase 2 Plan 04: Real Codebase Token Savings Summary

**[Substantive one-liner - average savings on real codebases and Assumption 1 verdict]**

## Accomplishments

- Created real codebase token savings test on X diverse projects
- Measured baseline vs optimized tokens across file size categories
- Calculated average savings: X% (vs ≥50% target, 23% validation)
- Synthesized Phase 2 findings into comprehensive Assumption 1 assessment
- **Phase 2 complete**: All 4 verification plans executed

## Files Created/Modified

- `audit/tests/test_real_codebase_savings.py` - Real codebase test
- `audit/evidence/real_codebase_savings_*.jsonl` - Test evidence
- `audit/reports/02-04-real-codebase-savings.md` - Savings findings
- `audit/reports/02-PHASE-SYNTHESIS.md` - Phase 2 comprehensive assessment

## Decisions Made

**Assumption 1 Verdict**: [Validated / Partially Validated / Not Validated]
- Progressive disclosure: [findings from 02-01]
- Dependency tracking: [findings from 02-02]
- Bypass behavior: [findings from 02-03]
- Real-world savings: [findings from this plan]

**Recommendations for Phase 12:**
- [Critical fixes if assumption violated]
- [Enhancements if minor gaps identified]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Phase Readiness

Phase 2 complete. Ready for Phase 3: AuZoom Structural Compliance.

**Phase 2 deliverables:**
- 4 test suites (progressive disclosure, dependency tracking, bypass behavior, real codebase savings)
- 5 reports (one per plan + synthesis)
- Comprehensive Assumption 1 verification with evidence

No blockers for Phase 3.
</output>
